{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš€ Task 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the training dataset\n",
    "train_path = \"/mnt/data/train.csv\"\n",
    "df_train = pd.read_csv(train_path)\n",
    "\n",
    "# Load the testing dataset\n",
    "test_path = \"/mnt/data/test.csv\"\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "# Display both datasets\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"TREC Training Dataset\", dataframe=df_train)\n",
    "tools.display_dataframe_to_user(name=\"TREC Testing Dataset\", dataframe=df_test)\n",
    "\n",
    "print(\"âœ… Training and Testing datasets loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš€ Task 2: Train a Doc2Vec Model for Coarse Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Prepare tagged documents\n",
    "train_tagged = [TaggedDocument(words=row.split(), tags=[str(i)]) for i, row in enumerate(df_train[\"question\"])]\n",
    "test_tagged = [TaggedDocument(words=row.split(), tags=[str(i + len(df_train))]) for i, row in enumerate(df_test[\"question\"])]\n",
    "\n",
    "# Train Doc2Vec model\n",
    "doc2vec_model = Doc2Vec(vector_size=300, window=4, min_count=2, workers=4, epochs=20)\n",
    "doc2vec_model.build_vocab(train_tagged)\n",
    "doc2vec_model.train(train_tagged, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "\n",
    "# Extract embeddings\n",
    "X_train = [doc2vec_model.dv[str(i)] for i in range(len(df_train))]\n",
    "X_test = [doc2vec_model.dv[str(i + len(df_train))] for i in range(len(df_test))]\n",
    "\n",
    "# Get labels\n",
    "y_train = df_train[\"coarse_label\"]\n",
    "y_test = df_test[\"coarse_label\"]\n",
    "\n",
    "# Train logistic regression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "print(f\"âœ… Macro F1 Score (Doc2Vec + Logistic Regression): {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš€ Task 3: Train LoRA Adapter on BERT (Coarse Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from adapters import LoRAConfig\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"question\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "test_dataset = Dataset.from_pandas(df_test)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Load BERT model with LoRA Adapter\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(df_train[\"coarse_label\"].unique()))\n",
    "config = LoRAConfig(target_modules=[\"query\", \"value\"])\n",
    "model.add_adapter(\"lora_adapter\", config)\n",
    "model.train_adapter(\"lora_adapter\")\n",
    "\n",
    "# Training settings\n",
    "training_args = TrainingArguments(output_dir=\"./results\", per_device_train_batch_size=8, num_train_epochs=3)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset)\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "print(\"âœ… LoRA Adapter trained successfully on BERT (Coarse Labels)!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš€ Task 4: Fine-tune BERT on Coarse Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT model\n",
    "full_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(df_train[\"coarse_label\"].unique()))\n",
    "\n",
    "# Training settings\n",
    "full_training_args = TrainingArguments(output_dir=\"./full_results\", per_device_train_batch_size=8, num_train_epochs=3)\n",
    "full_trainer = Trainer(model=full_model, args=full_training_args, train_dataset=train_dataset)\n",
    "\n",
    "# Train model\n",
    "full_trainer.train()\n",
    "\n",
    "print(\"âœ… Full BERT Fine-tuned on Coarse Labels!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš€ Task 5: Evaluate All Models on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Evaluate Doc2Vec Model\n",
    "start_time = time.time()\n",
    "y_pred_doc2vec = lr_model.predict(X_test)\n",
    "f1_doc2vec = f1_score(y_test, y_pred_doc2vec, average=\"macro\")\n",
    "doc2vec_time = time.time() - start_time\n",
    "\n",
    "# Evaluate LoRA Adapter Model\n",
    "start_time = time.time()\n",
    "lora_predictions = trainer.predict(test_dataset)\n",
    "lora_f1 = f1_score(y_test, lora_predictions.predictions.argmax(axis=-1), average=\"macro\")\n",
    "lora_time = time.time() - start_time\n",
    "\n",
    "# Evaluate Fully Fine-tuned BERT\n",
    "start_time = time.time()\n",
    "bert_predictions = full_trainer.predict(test_dataset)\n",
    "bert_f1 = f1_score(y_test, bert_predictions.predictions.argmax(axis=-1), average=\"macro\")\n",
    "bert_time = time.time() - start_time\n",
    "\n",
    "# Compare Results\n",
    "print(f\"âœ… Doc2Vec Model - Macro F1: {f1_doc2vec:.4f}, Training Time: {doc2vec_time:.2f}s\")\n",
    "print(f\"âœ… LoRA Adapter Model - Macro F1: {lora_f1:.4f}, Training Time: {lora_time:.2f}s\")\n",
    "print(f\"âœ… Fine-tuned BERT Model - Macro F1: {bert_f1:.4f}, Training Time: {bert_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš€ Task 6: Repeat for Fine Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update labels for fine-grained classification\n",
    "y_train_fine = df_train[\"fine_label\"]\n",
    "y_test_fine = df_test[\"fine_label\"]\n",
    "\n",
    "# Repeat Doc2Vec + Logistic Regression\n",
    "lr_model.fit(X_train, y_train_fine)\n",
    "y_pred_fine_doc2vec = lr_model.predict(X_test)\n",
    "f1_fine_doc2vec = f1_score(y_test_fine, y_pred_fine_doc2vec, average=\"macro\")\n",
    "\n",
    "# Repeat LoRA Adapter Training\n",
    "trainer.train()\n",
    "lora_predictions_fine = trainer.predict(test_dataset)\n",
    "lora_fine_f1 = f1_score(y_test_fine, lora_predictions_fine.predictions.argmax(axis=-1), average=\"macro\")\n",
    "\n",
    "# Repeat Full BERT Training\n",
    "full_trainer.train()\n",
    "bert_predictions_fine = full_trainer.predict(test_dataset)\n",
    "bert_fine_f1 = f1_score(y_test_fine, bert_predictions_fine.predictions.argmax(axis=-1), average=\"macro\")\n",
    "\n",
    "# Compare Results\n",
    "print(f\"âœ… Fine Labels - Doc2Vec F1: {f1_fine_doc2vec:.4f}\")\n",
    "print(f\"âœ… Fine Labels - LoRA Adapter F1: {lora_fine_f1:.4f}\")\n",
    "print(f\"âœ… Fine Labels - Fine-tuned BERT F1: {bert_fine_f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exam_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
