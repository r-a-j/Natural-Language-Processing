{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ Task 1: Load Dataset & Seed Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Emotion dataset loaded successfully!\n",
      "‚úÖ Seed words loaded successfully!\n",
      "{'anger': ['outrageous', 'infuriating', 'ridiculous', 'absurd', 'exasperating', 'disgusting', 'insulting', 'offensive', 'intolerable', 'unacceptable', 'outrage', 'insane', 'angry', 'upset', 'boiling', 'seething', 'frustrated', 'mad', 'irritated', 'livid', 'indignant', 'agitated', 'annoyed', 'pissed', 'irate', 'aggravated', 'enraged', 'bitter', 'displeased', 'disgruntled', 'vexed', 'temperamental', 'cross', 'testy', 'impatient', 'belligerent', 'furious', 'hostile', 'offended', 'exasperated', 'resentful'], 'sadness': ['sad', 'unhappy', 'melancholy', 'dejected', 'mournful', 'downcast', 'despondent', 'blue', 'dismal', 'gloomy', 'forlorn', 'heartbroken', 'woeful', 'crestfallen', 'disheartened', 'grief', 'sorrowful', 'tearful', 'somber', 'bereaved', 'lamenting', 'doleful', 'mournful', 'lugubrious', 'pensive', 'heavyhearted', 'woebegone', 'troubled', 'depressed', 'brokenhearted', 'weepy', 'funereal', 'downhearted', 'low-spirited', 'sullen', 'despairing', 'disconsolate', 'downtrodden', 'dejected', 'wretched', 'grief', 'painful', 'miserable', 'anguished', 'regretful'], 'joy': ['happy', 'joyful', 'delighted', 'cheerful', 'ecstatic', 'exuberant', 'jovial', 'elated', 'content', 'pleased', 'gleeful', 'upbeat', 'excited', 'overjoyed', 'radiant', 'smiling', 'grateful', 'blissful', 'euphoric', 'lighthearted', 'satisfied', 'thrilled', 'bubbly', 'vibrant', 'exhilarated', 'festive', 'merry', 'sunny', 'jubilant', 'carefree', 'optimistic', 'sparkling', 'heartwarming', 'buoyant', 'blessed', 'uplifting', 'cheery', 'grinning', 'animated', 'satisfying', 'delightful', 'smiley', 'gleaming', 'positive', 'wonderful'], 'optimism': ['optimistic', 'hopeful', 'positive', 'encouraging', 'upbeat', 'confident', 'cheerful', 'buoyant', 'inspiring', 'joyful', 'assured', 'sanguine', 'expectant', 'enthusiastic', 'confident', 'uplifting', 'auspicious', 'bright', 'promising', 'hope-filled', 'sunny', 'assuring', 'heartening', 'favorable', 'constructive', 'forward-looking', 'high-spirited', 'hope-giving', 'rosy', 'promising', 'confident', 'reassuring', 'promising', 'reassured', 'promising', 'encouraged', 'spirited', 'promising', 'inspired', 'promising', 'hopeful', 'promising', 'positive', 'promising', 'upbeat']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rajubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Load the emotion dataset\n",
    "dataset_path = \"emotion_dataset.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Display the dataset\n",
    "df.head()\n",
    "\n",
    "print(\"‚úÖ Emotion dataset loaded successfully!\")\n",
    "\n",
    "# Load seed words (if available)\n",
    "seed_words_path = \"seed_words.json\"\n",
    "\n",
    "try:\n",
    "    with open(seed_words_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        seed_words = json.load(file)\n",
    "    print(\"‚úÖ Seed words loaded successfully!\")\n",
    "    print(seed_words)\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Seed words file not found. Please upload 'seed_words.json'!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ Task 2: Preprocessing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Text preprocessing completed!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load Spacy Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation & special characters\n",
    "    doc = nlp(text)  # Tokenize & Lemmatize\n",
    "    words = [token.lemma_ for token in doc if token.is_alpha and token.text not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply preprocessing\n",
    "df[\"processed_text\"] = df[\"text\"].astype(str).apply(preprocess_text)\n",
    "\n",
    "# Display cleaned data\n",
    "df[[\"text\", \"processed_text\"]]\n",
    "\n",
    "print(\"‚úÖ Text preprocessing completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ Task 3: Train 5 LDAs with K=4 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lda_model import LDA_Model  # Load custom LDA model from Moodle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Convert text into a document-term matrix (DTM)\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "X = vectorizer.fit_transform(df[\"processed_text\"])\n",
    "\n",
    "# Train 5 LDA models\n",
    "lda_models = []\n",
    "for i in range(5):\n",
    "    lda = LDA_Model(n_topics=4, n_iter=500, random_state=i)  # Set high `n_iter` value\n",
    "    lda.fit(X)\n",
    "    lda_models.append(lda)\n",
    "    print(f\"‚úÖ LDA Model {i+1} trained successfully!\")\n",
    "\n",
    "# Save models for later use\n",
    "lda_models_dict = {f\"LDA_{i+1}\": lda for i, lda in enumerate(lda_models)}\n",
    "print(\"‚úÖ All 5 LDA models trained and saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ Task 4: Train a Seeded LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lda_model import SeededLDA_Model  # Load Seeded LDA model from Moodle\n",
    "\n",
    "# Ensure seed words are available\n",
    "if \"seed_words\" in locals():\n",
    "    # Train Seeded LDA model\n",
    "    seeded_lda = SeededLDA_Model(n_topics=4, n_iter=500, random_state=42, seed_words=seed_words)\n",
    "    seeded_lda.fit(X)\n",
    "    \n",
    "    # Display the top words for each topic\n",
    "    topics = seeded_lda.display_topics(vectorizer)\n",
    "    print(\"‚úÖ Seeded LDA trained successfully! Top words per topic:\")\n",
    "    for topic_num, words in topics.items():\n",
    "        print(f\"Topic {topic_num}: {', '.join(words)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Seed words not found. Please check 'seed_words.json'!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ Task 5: Evaluate with Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to get the dominant topic for each document\n",
    "def get_dominant_topic(model, X):\n",
    "    return model.documents_to_topic_model(X)\n",
    "\n",
    "# Compute dominant topics for each LDA model\n",
    "lda_results = {f\"LDA_{i+1}\": get_dominant_topic(lda, X) for i, lda in enumerate(lda_models)}\n",
    "\n",
    "# Compute dominant topics for Seeded LDA\n",
    "seeded_lda_results = get_dominant_topic(seeded_lda, X)\n",
    "\n",
    "# Convert true labels to numerical format\n",
    "label_mapping = {\"anger\": 0, \"joy\": 1, \"sadness\": 2, \"optimism\": 3}\n",
    "true_labels = df[\"emotion\"].map(label_mapping)\n",
    "\n",
    "# Compare each LDA model using confusion matrix\n",
    "for model_name, preds in lda_results.items():\n",
    "    cm = confusion_matrix(true_labels, preds)\n",
    "    \n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"‚úÖ Confusion matrix for {model_name} displayed!\")\n",
    "\n",
    "# Compare Seeded LDA using confusion matrix\n",
    "cm_seeded = confusion_matrix(true_labels, seeded_lda_results)\n",
    "\n",
    "# Plot Confusion Matrix for Seeded LDA\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm_seeded, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix - Seeded LDA\")\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Confusion matrix for Seeded LDA displayed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exam_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
