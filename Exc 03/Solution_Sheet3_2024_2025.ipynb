{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Load and Read Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book 1 preview:\n",
      " HARRY \n",
      "\n",
      "POTTER \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DUDLEY DEMENTED \n",
      "\n",
      "The hottest day of the summer so far was drawing to \n",
      "a close and a drowsy silence lay over the large, square \n",
      "houses of Privet Drive. Cars that were usually \n",
      "gleaming stood dusty in their drives and lawns that \n",
      "were once emerald green lay parched and yellowing; \n",
      "the use of hosepipes had been banned due to \n",
      "drought. Deprived of their usual car-washing and \n",
      "lawn-mowing pursuits, the inhabitants of Privet Drive \n",
      "had retreated into the shade of their cool \n",
      "--------------------------------------------------\n",
      "Book 2 preview:\n",
      " / \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "OWL POST \n",
      "\n",
      "Harry Potter was a highly unusual boy in many ways. \n",
      "For one thing, he hated the summer holidays more \n",
      "than any other time of year. For another, he really \n",
      "wanted to do his homework but was forced to do it in \n",
      "secret, in the dead of night. And he also happened to \n",
      "be a wizard. \n",
      "\n",
      "It was nearly midnight, and he was lying on his \n",
      "stomach in bed, the blankets drawn right over his \n",
      "head like a tent, a flashlight in one hand and a large \n",
      "leather-bound book (A History of Magic by Bath \n",
      "--------------------------------------------------\n",
      "Book 3 preview:\n",
      " \n",
      "J . K . R O W L ! N G \n",
      "\n",
      "HARRY \n",
      "\n",
      "POTTER \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE WORST BIRTHDAY \n",
      "\n",
      "Not for the first time, an argument had broken out \n",
      "over breakfast at number four, Privet Drive. Mr. \n",
      "Vernon Dursley had been woken in the early hours of \n",
      "the morning by a loud, hooting noise from his nephew \n",
      "Harry’s room. \n",
      "\n",
      "“Third time this week!” he roared across the table. “If \n",
      "you can’t control that owl, it’ll have to go!” \n",
      "\n",
      "Harry tried, yet again, to explain. \n",
      "\n",
      "“She’s bored,” he said. “She’s used to flying around \n",
      "outs \n",
      "--------------------------------------------------\n",
      "Book 4 preview:\n",
      " / \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE RIDDLE HOUSE \n",
      "\n",
      "The villagers of Little Hangleton still called it “the \n",
      "Riddle House,” even though it had been many years \n",
      "since the Riddle family had lived there. It stood on a \n",
      "hill overlooking the village, some of its windows \n",
      "boarded, tiles missing from its roof, and ivy spreading \n",
      "unchecked over its face. Once a fine-looking manor, \n",
      "and easily the largest and grandest building for miles \n",
      "around, the Riddle House was now damp, derelict, \n",
      "and unoccupied. \n",
      "\n",
      "The Little Hangletons all  \n",
      "--------------------------------------------------\n",
      "Book 5 preview:\n",
      " I \n",
      "\n",
      "\n",
      "\n",
      "* \n",
      "\n",
      "THE DARK LORD ASCENDING \n",
      "\n",
      "The two men appeared out of nowhere, a few yards \n",
      "apart in the narrow, moonlit lane. For a second they \n",
      "stood quite still, wands directed at each other’s \n",
      "chests; then, recognizing each other, they stowed \n",
      "their wands beneath their cloaks and started walking \n",
      "briskly in the same direction. \n",
      "\n",
      "“News?” asked the taller of the two. \n",
      "\n",
      "“The best,” replied Severus Snape. \n",
      "\n",
      "The lane was bordered on the left by wild, low- \n",
      "growing brambles, on the right by a high, neat \n",
      "--------------------------------------------------\n",
      "Book 6 preview:\n",
      " \n",
      "* J \n",
      "\n",
      "\n",
      "\n",
      "/ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE OTHER MINISTER \n",
      "\n",
      "It was nearing midnight and the Prime Minister was \n",
      "sitting alone in his office, reading a long memo that \n",
      "was slipping through his brain without leaving the \n",
      "slightest trace of meaning behind. He was waiting for \n",
      "a call from the President of a far distant country, and \n",
      "between wondering when the wretched man would \n",
      "telephone, and trying to suppress unpleasant \n",
      "memories of what had been a very long, tiring, and \n",
      "difficult week, there was not much space in his \n",
      "--------------------------------------------------\n",
      "Book 7 preview:\n",
      " / \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE BOY WHO LIVED \n",
      "\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, \n",
      "were proud to say that they were perfectly normal, \n",
      "thank you very much. They were the last people you’d \n",
      "expect to be involved in anything strange or \n",
      "mysterious, because they just didn’t hold with such \n",
      "nonsense. \n",
      "\n",
      "Mr. Dursley was the director of a firm called \n",
      "Grunnings, which made drills. He was a big, beefy \n",
      "man with hardly any neck, although he did have a \n",
      "very large mustache. Mrs. Dursley was thin and \n",
      "blonde  \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = \"potter\"  # If it's in the current working directory\n",
    "\n",
    "# Get all text files in the folder\n",
    "file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(\".txt\")]\n",
    "\n",
    "# Read all books into a list\n",
    "books = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        books.append(file.read())\n",
    "\n",
    "# Display a snippet of each book to verify loading\n",
    "for i, book in enumerate(books):\n",
    "    print(f\"Book {i+1} preview:\\n\", book[:500], \"\\n\" + \"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Extract Book Titles Using Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book 1: Harry Potter and the Order of the Phoenix\n",
      "Book 2: Harry Potter and the Prisoner of Azkaban\n",
      "Book 3: Harry Potter and the Chamber of Secrets\n",
      "Book 4: Harry Potter and the Goblet of Fire\n",
      "Book 5: Harry Potter and the Deathly Hallows\n",
      "Book 6: Harry Potter and the Half Blood Prince\n",
      "Book 7: Harry Potter and the Philosophers Stone\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to extract book title\n",
    "def extract_title(text):\n",
    "    match = re.search(r\"Page \\| \\d+ (.*?) - J\\.K\\. Rowling\", text)\n",
    "    return match.group(1) if match else \"Unknown Title\"\n",
    "\n",
    "# Extract titles\n",
    "book_titles = [extract_title(book) for book in books]\n",
    "\n",
    "# Display extracted titles\n",
    "for i, title in enumerate(book_titles):\n",
    "    print(f\"Book {i+1}: {title}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Books:   0%|          | 0/7 [00:57<?, ?book/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m cleaned_books \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m book \u001b[38;5;129;01min\u001b[39;00m tqdm(books, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleaning Books\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbook\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 28\u001b[0m     cleaned_books\u001b[38;5;241m.\u001b[39mappend(\u001b[43mclean_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbook\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Display snippet of cleaned text\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, book \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cleaned_books):\n",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mclean_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     12\u001b[0m text \u001b[38;5;241m=\u001b[39m page_indicator_pattern\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Trim content before first chapter\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mchapter_trim_pattern\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCHAPTER\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Remove chapter headers (all caps)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m text \u001b[38;5;241m=\u001b[39m chapter_header_pattern\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, text)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Precompile regex patterns for better performance\n",
    "page_indicator_pattern = re.compile(r\"Page \\| \\d+ .*? - J\\.K\\. Rowling\")\n",
    "chapter_trim_pattern = re.compile(r\".*?CHAPTER\", re.DOTALL)\n",
    "chapter_header_pattern = re.compile(r\"\\n[A-Z\\s]+\\n\")\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Remove page indicators\n",
    "    text = page_indicator_pattern.sub(\"\", text)\n",
    "\n",
    "    # Trim content before first chapter\n",
    "    text = chapter_trim_pattern.sub(\"CHAPTER\", text)\n",
    "\n",
    "    # Remove chapter headers (all caps)\n",
    "    text = chapter_header_pattern.sub(\"\\n\", text)\n",
    "\n",
    "    # Replace line breaks with spaces\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "# Apply cleaning with tqdm progress bar\n",
    "cleaned_books = []\n",
    "for book in tqdm(books, desc=\"Cleaning Books\", unit=\"book\"):\n",
    "    cleaned_books.append(clean_text(book))\n",
    "\n",
    "# Display snippet of cleaned text\n",
    "for i, book in enumerate(cleaned_books):\n",
    "    print(f\"Book {i+1} cleaned preview:\\n\", book[:500], \"\\n\" + \"-\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cudf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcudf\u001b[39;00m  \u001b[38;5;66;03m# RAPIDS GPU DataFrame\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cudf'"
     ]
    }
   ],
   "source": [
    "import cudf  # RAPIDS GPU DataFrame\n",
    "import cupy as cp\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Convert list to cuDF DataFrame\n",
    "df_gpu = cudf.DataFrame({\"book_text\": books})\n",
    "\n",
    "# Precompile regex patterns for GPU efficiency\n",
    "page_indicator_pattern = re.compile(r\"Page \\| \\d+ .*? - J\\.K\\. Rowling\")\n",
    "chapter_trim_pattern = re.compile(r\".*?CHAPTER\", re.DOTALL)\n",
    "chapter_header_pattern = re.compile(r\"\\n[A-Z\\s]+\\n\")\n",
    "\n",
    "# Define GPU-accelerated cleaning function\n",
    "def clean_text_gpu(text):\n",
    "    text = page_indicator_pattern.sub(\"\", text)  # Remove page indicators\n",
    "    text = chapter_trim_pattern.sub(\"CHAPTER\", text)  # Trim before first chapter\n",
    "    text = chapter_header_pattern.sub(\"\\n\", text)  # Remove all-caps chapter headers\n",
    "    text = text.replace(\"\\n\", \" \")  # Replace newlines with spaces\n",
    "    return text.strip()\n",
    "\n",
    "# Apply cleaning function on GPU\n",
    "df_gpu[\"cleaned_text\"] = df_gpu[\"book_text\"].applymap(clean_text_gpu)\n",
    "\n",
    "# Convert back to Pandas for compatibility (if needed)\n",
    "cleaned_books = df_gpu[\"cleaned_text\"].to_pandas().tolist()\n",
    "\n",
    "# Display progress and verify\n",
    "for i, book in enumerate(cleaned_books[:3]):  # Show only first 3 books\n",
    "    print(f\"Book {i+1} cleaned preview:\\n\", book[:500], \"\\n\" + \"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rajubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/rajubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_books' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m words\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Apply preprocessing\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m preprocessed_books \u001b[38;5;241m=\u001b[39m [preprocess_text(book) \u001b[38;5;28;01mfor\u001b[39;00m book \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcleaned_books\u001b[49m]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Display snippet of processed text\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, book \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(preprocessed_books):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaned_books' is not defined"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation and numbers\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "    # Tokenization and lemmatization\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "\n",
    "    return words\n",
    "\n",
    "# Apply preprocessing\n",
    "preprocessed_books = [preprocess_text(book) for book in cleaned_books]\n",
    "\n",
    "# Display snippet of processed text\n",
    "for i, book in enumerate(preprocessed_books):\n",
    "    print(f\"Book {i+1} processed preview:\\n\", book[:20], \"\\n\" + \"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Calculate TF-IDF and Find Important Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_books' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Convert list of lists into list of strings\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m book_strings \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(book) \u001b[38;5;28;01mfor\u001b[39;00m book \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpreprocessed_books\u001b[49m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize TF-IDF vectorizer\u001b[39;00m\n\u001b[1;32m      7\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessed_books' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convert list of lists into list of strings\n",
    "book_strings = [\" \".join(book) for book in preprocessed_books]\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(book_strings)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Extract top words per book\n",
    "def top_tfidf_words(tfidf_matrix, feature_names, book_index, top_n=10):\n",
    "    row = tfidf_matrix[book_index].toarray()[0]\n",
    "    top_indices = row.argsort()[-top_n:][::-1]\n",
    "    return [(feature_names[i], row[i]) for i in top_indices]\n",
    "\n",
    "# Display top words for each book\n",
    "for i, title in enumerate(book_titles):\n",
    "    print(f\"\\nTop words for '{title}':\")\n",
    "    print(top_tfidf_words(tfidf_matrix, feature_names, i))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exam_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
