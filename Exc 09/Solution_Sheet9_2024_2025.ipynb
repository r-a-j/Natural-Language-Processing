{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš€ Task 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the character dataset\n",
    "characters_path = \"characters.csv\"\n",
    "df_characters = pd.read_csv(characters_path)\n",
    "\n",
    "# Display the character dataset\n",
    "df_characters.head()\n",
    "\n",
    "print(\"âœ… Characters dataset loaded successfully!\")\n",
    "\n",
    "# Load the episode transcripts\n",
    "trek_path = \"trek.json\"\n",
    "with open(trek_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    trek_transcripts = json.load(file)\n",
    "\n",
    "# Display some transcripts\n",
    "print(\"âœ… Trek transcripts loaded successfully!\")\n",
    "print(json.dumps(trek_transcripts, indent=2)[:2000])  # Display first part of JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš€ Task 2: Preprocessing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "# Load Spacy Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"o'brien\", \"obrien\", text)  # Remove apostrophe from O'Brien\n",
    "    text = re.sub(r\"t'pol\", \"tpol\", text)  # Remove apostrophe from T'Pol\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation & special characters\n",
    "    doc = nlp(text)  # Tokenize & Lemmatize\n",
    "    words = [token.lemma_ for token in doc if token.is_alpha]\n",
    "    return words\n",
    "\n",
    "# Apply preprocessing to all transcripts\n",
    "processed_transcripts = {show: [preprocess_text(ep) for ep in episodes] for show, episodes in trek_transcripts.items()}\n",
    "\n",
    "print(\"âœ… Text preprocessing completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš€ Task 3: Train Two Word2Vec Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Flatten transcripts into a list of sentences\n",
    "all_sentences = [sentence for episodes in processed_transcripts.values() for episode in episodes for sentence in episode]\n",
    "\n",
    "# Train Word2Vec with window size = 2\n",
    "w2v_model_2 = Word2Vec(sentences=all_sentences, vector_size=300, window=2, min_count=1, workers=4)\n",
    "\n",
    "# Train Word2Vec with window size = 10\n",
    "w2v_model_10 = Word2Vec(sentences=all_sentences, vector_size=300, window=10, min_count=1, workers=4)\n",
    "\n",
    "print(\"âœ… Two Word2Vec models trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš€ Task 4: Compute Cosine Similarities for Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "\n",
    "# Extract character names\n",
    "character_names = df_characters[\"name\"].str.lower().tolist()\n",
    "\n",
    "# Function to compute cosine similarity matrix\n",
    "def compute_similarity_matrix(model, character_list):\n",
    "    matrix = np.zeros((len(character_list), len(character_list)))\n",
    "    \n",
    "    for i, char1 in enumerate(character_list):\n",
    "        for j, char2 in enumerate(character_list):\n",
    "            if char1 in model.wv and char2 in model.wv:\n",
    "                matrix[i, j] = 1 - cosine(model.wv[char1], model.wv[char2])  # Cosine similarity\n",
    "            else:\n",
    "                matrix[i, j] = 0  # If character is missing, similarity = 0\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "# Compute similarity matrices for both models\n",
    "similarity_matrix_2 = compute_similarity_matrix(w2v_model_2, character_names)\n",
    "similarity_matrix_10 = compute_similarity_matrix(w2v_model_10, character_names)\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_similarity_2 = pd.DataFrame(similarity_matrix_2, index=character_names, columns=character_names)\n",
    "df_similarity_10 = pd.DataFrame(similarity_matrix_10, index=character_names, columns=character_names)\n",
    "\n",
    "df_similarity_2.head()\n",
    "df_similarity_10.head()\n",
    "\n",
    "print(\"âœ… Cosine similarity matrices computed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš€ Task 5: Compute Similarities for Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract character roles\n",
    "character_roles = df_characters[\"role\"].str.lower().tolist()\n",
    "\n",
    "# Compute similarity matrices for roles\n",
    "similarity_matrix_roles_2 = compute_similarity_matrix(w2v_model_2, character_roles)\n",
    "similarity_matrix_roles_10 = compute_similarity_matrix(w2v_model_10, character_roles)\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_similarity_roles_2 = pd.DataFrame(similarity_matrix_roles_2, index=character_roles, columns=character_roles)\n",
    "df_similarity_roles_10 = pd.DataFrame(similarity_matrix_roles_10, index=character_roles, columns=character_roles)\n",
    "\n",
    "df_similarity_roles_2.head()\n",
    "df_similarity_roles_10.head()\n",
    "\n",
    "print(\"âœ… Role-based similarity matrices computed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exam_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
